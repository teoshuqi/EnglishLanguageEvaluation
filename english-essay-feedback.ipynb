{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cd1519",
   "metadata": {
    "papermill": {
     "duration": 0.012937,
     "end_time": "2022-11-20T06:33:57.010587",
     "exception": false,
     "start_time": "2022-11-20T06:33:56.997650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidrectional Encoder Representation of Transformers (BERT)\n",
    "* Architecture\n",
    "  * Transformers (Encoder)\n",
    "    * Attention mechanism\n",
    "      * Multi headed self attention to associate different parts of sequences together\n",
    "      * Calculate a similarity score between the current token and the tokens in the sequence and use that as weights to get a new understanding of the sequence\n",
    "* Training\n",
    "   * Masked Language Modelling (MLM)\n",
    "   * Next Sentence Prediction (NSP)\n",
    " \n",
    "## Robustly Optimized BERT Pre-training Approach (RoBERTa)\n",
    "* Architecture\n",
    "  * Transformers (Encoder)\n",
    "    * Same as BERT\n",
    "* Training\n",
    "  * Longer training time \n",
    "  * Larger training data, batch size, vocab size\n",
    "  * Removal of NSP\n",
    "  * Dynamic masking for MLM by duplicating data and using different masking methods\n",
    " \n",
    "## Decoding-Enhanced BERT with Disentangled Attention (DeBERTa)\n",
    "* Architecture\n",
    "  * Transformers (Encoder)\n",
    "    * Disentagled Attention\n",
    "      * Attention broken down into dot product of content vectors of token *i* and *j*, content vector *i* to relative position vector *j* and relative position vector *j* to content vector *i*\n",
    "      * Compared to BERT/RoBERTa, dot product of sum(content, absolute position) of *i* and sum(content, absolute position) of *j*\n",
    "      * This way, the relationship/similarity of word at *i* and *j* can be fully explored by explicitly comparing the content of the words and the content and position of the respective words. \n",
    "      * Summing everything into a single vector before comparing may hide certain important patterns in the content/position of the words\n",
    "    * Enhanced Mask Decoding\n",
    "      * Incoporate absolute positions into the model by adding it in after all the Transformer layers\n",
    "      * Add a bit more information about the exact position of word (E.g. front or back of sentence)\n",
    "* Training\n",
    "  * Scale invariant Fine Tuning (SiFT)\n",
    "     * Normalise embedding then add pertubations to the vector before fine tuning\n",
    "     * Normalising the vector will help to reduce variation in vector due to different words/models\n",
    "     * Help model to generalise better by teaching the model to recognise similar inputs, thus becoming less sensitive to small changes, less overfitting as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8817bb2e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-20T06:33:57.036545Z",
     "iopub.status.busy": "2022-11-20T06:33:57.035952Z",
     "iopub.status.idle": "2022-11-20T06:34:03.563177Z",
     "shell.execute_reply": "2022-11-20T06:34:03.562131Z"
    },
    "papermill": {
     "duration": 6.542207,
     "end_time": "2022-11-20T06:34:03.565897",
     "exception": false,
     "start_time": "2022-11-20T06:33:57.023690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow_addons as tfa  \n",
    "from transformers import AutoTokenizer, TFAutoModel, AutoConfig\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import mixed_precision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "import math\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506f05b",
   "metadata": {
    "papermill": {
     "duration": 0.005876,
     "end_time": "2022-11-20T06:34:03.578326",
     "exception": false,
     "start_time": "2022-11-20T06:34:03.572450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946529b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:03.593061Z",
     "iopub.status.busy": "2022-11-20T06:34:03.591366Z",
     "iopub.status.idle": "2022-11-20T06:34:03.597437Z",
     "shell.execute_reply": "2022-11-20T06:34:03.596578Z"
    },
    "papermill": {
     "duration": 0.014933,
     "end_time": "2022-11-20T06:34:03.599354",
     "exception": false,
     "start_time": "2022-11-20T06:34:03.584421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET = '../input/feedback-prize-english-language-learning/train.csv'\n",
    "TEST_DATASET = '../input/feedback-prize-english-language-learning/test.csv'\n",
    "Y_VARIABLES = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'] \n",
    "DEBERTA_MODEL = '../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/' #'../input/roberta-base/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbff7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:03.612741Z",
     "iopub.status.busy": "2022-11-20T06:34:03.611869Z",
     "iopub.status.idle": "2022-11-20T06:34:05.913567Z",
     "shell.execute_reply": "2022-11-20T06:34:05.912451Z"
    },
    "papermill": {
     "duration": 2.313477,
     "end_time": "2022-11-20T06:34:05.918572",
     "exception": false,
     "start_time": "2022-11-20T06:34:03.605095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 06:34:03.679688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:03.770666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:03.771442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:03.782787: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 06:34:03.783119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:03.783838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:03.784649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:05.901316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:05.902242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:05.903042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 06:34:05.903729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a5d38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:05.934096Z",
     "iopub.status.busy": "2022-11-20T06:34:05.933165Z",
     "iopub.status.idle": "2022-11-20T06:34:05.937335Z",
     "shell.execute_reply": "2022-11-20T06:34:05.936719Z"
    },
    "papermill": {
     "duration": 0.014104,
     "end_time": "2022-11-20T06:34:05.939132",
     "exception": false,
     "start_time": "2022-11-20T06:34:05.925028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Equivalent to the two lines above\n",
    "# mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8335c7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:05.953484Z",
     "iopub.status.busy": "2022-11-20T06:34:05.951941Z",
     "iopub.status.idle": "2022-11-20T06:34:05.958010Z",
     "shell.execute_reply": "2022-11-20T06:34:05.957228Z"
    },
    "papermill": {
     "duration": 0.014962,
     "end_time": "2022-11-20T06:34:05.959974",
     "exception": false,
     "start_time": "2022-11-20T06:34:05.945012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self):\n",
    "        self.num_fc_units = 32\n",
    "        self.batch_size = 4\n",
    "        self.epochs = 20\n",
    "        self.seq_len = 512\n",
    "        self.kfolds = 5\n",
    "        self.regr_units = 6\n",
    "        self.l2_alpha = 0.0001\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1218d3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:05.973591Z",
     "iopub.status.busy": "2022-11-20T06:34:05.972871Z",
     "iopub.status.idle": "2022-11-20T06:34:05.977477Z",
     "shell.execute_reply": "2022-11-20T06:34:05.976882Z"
    },
    "papermill": {
     "duration": 0.013241,
     "end_time": "2022-11-20T06:34:05.979225",
     "exception": false,
     "start_time": "2022-11-20T06:34:05.965984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0bb9f5",
   "metadata": {
    "papermill": {
     "duration": 0.005849,
     "end_time": "2022-11-20T06:34:05.990904",
     "exception": false,
     "start_time": "2022-11-20T06:34:05.985055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee35873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:06.004066Z",
     "iopub.status.busy": "2022-11-20T06:34:06.003323Z",
     "iopub.status.idle": "2022-11-20T06:34:06.010281Z",
     "shell.execute_reply": "2022-11-20T06:34:06.009302Z"
    },
    "papermill": {
     "duration": 0.015563,
     "end_time": "2022-11-20T06:34:06.012364",
     "exception": false,
     "start_time": "2022-11-20T06:34:05.996801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_valid_split(data, percent=0.8):\n",
    "    ranges = range(data.shape[0])\n",
    "    prop = math.ceil(percent*data.shape[0])\n",
    "    train_idx = sample(ranges, prop)\n",
    "    valid_idx = [i for i in ranges if i not in train_idx]\n",
    "    return train_idx, valid_idx\n",
    "\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    mcrmse = tf.reduce_mean(tf.sqrt(mse), axis=-1, keepdims=True)\n",
    "    return mcrmse\n",
    "\n",
    "def clean_text(text):\n",
    "    new_text = re.sub(r\"[\\n\\r\\t]\", ' ', text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d8dcf",
   "metadata": {
    "papermill": {
     "duration": 0.005711,
     "end_time": "2022-11-20T06:34:06.023887",
     "exception": false,
     "start_time": "2022-11-20T06:34:06.018176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212ab936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:06.036960Z",
     "iopub.status.busy": "2022-11-20T06:34:06.036624Z",
     "iopub.status.idle": "2022-11-20T06:34:06.315200Z",
     "shell.execute_reply": "2022-11-20T06:34:06.314246Z"
    },
    "papermill": {
     "duration": 0.287867,
     "end_time": "2022-11-20T06:34:06.317773",
     "exception": false,
     "start_time": "2022-11-20T06:34:06.029906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_DATASET)\n",
    "test_df = pd.read_csv(TEST_DATASET)\n",
    "\n",
    "X_train = df['full_text'].apply(lambda x: clean_text(x))\n",
    "Y_train = df[Y_VARIABLES]\n",
    "\n",
    "X_test = test_df['full_text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419509bb",
   "metadata": {
    "papermill": {
     "duration": 0.005675,
     "end_time": "2022-11-20T06:34:06.329535",
     "exception": false,
     "start_time": "2022-11-20T06:34:06.323860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96fee3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:06.343768Z",
     "iopub.status.busy": "2022-11-20T06:34:06.342326Z",
     "iopub.status.idle": "2022-11-20T06:34:07.050160Z",
     "shell.execute_reply": "2022-11-20T06:34:07.048566Z"
    },
    "papermill": {
     "duration": 0.721893,
     "end_time": "2022-11-20T06:34:07.057320",
     "exception": false,
     "start_time": "2022-11-20T06:34:06.335427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "deberta_tokenizer = AutoTokenizer.from_pretrained(DEBERTA_MODEL, use_fast=False)\n",
    "deberta_config = AutoConfig.from_pretrained(DEBERTA_MODEL)\n",
    "deberta_config.attention_probs_dropout_prob = 0.0\n",
    "deberta_config.hidden_dropout_prob = 0.0\n",
    "deberta_config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75313c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.071836Z",
     "iopub.status.busy": "2022-11-20T06:34:07.071503Z",
     "iopub.status.idle": "2022-11-20T06:34:07.081550Z",
     "shell.execute_reply": "2022-11-20T06:34:07.080627Z"
    },
    "papermill": {
     "duration": 0.019315,
     "end_time": "2022-11-20T06:34:07.083468",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.064153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_tokenize(data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for text in data:\n",
    "        data_token = deberta_tokenizer(text, add_special_tokens=True,  max_length=HPARAMS.seq_len, return_attention_mask=True, \n",
    "                                   return_tensors=\"np\",truncation=True,  padding='max_length')\n",
    "        input_ids.append(data_token['input_ids'][0])\n",
    "        attention_masks.append(data_token['attention_mask'][0])\n",
    "    result = {\n",
    "        'input_ids':np.array(input_ids, dtype='int32'),\n",
    "        'attention_masks':np.array(attention_masks, dtype='int32')\n",
    "    }\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1599302e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.096531Z",
     "iopub.status.busy": "2022-11-20T06:34:07.096267Z",
     "iopub.status.idle": "2022-11-20T06:34:07.102368Z",
     "shell.execute_reply": "2022-11-20T06:34:07.101452Z"
    },
    "papermill": {
     "duration": 0.014827,
     "end_time": "2022-11-20T06:34:07.104330",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.089503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightedAverage(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(WeightedAverage, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='w',\n",
    "                    shape=(1, input_shape[-1]),\n",
    "                    initializer='uniform',\n",
    "                    dtype=tf.float32,\n",
    "                    trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "\n",
    "        # inputs is a list of tensor of shape [(n_batch, n_feat), ..., (n_batch, n_feat)]\n",
    "        # expand last dim of each input passed [(n_batch, n_feat, 1), ..., (n_batch, n_feat, 1)]\n",
    "        weights = tf.nn.softmax(self.W, axis=-1) # (1,1,n_inputs)\n",
    "        # weights sum up to one on last dim\n",
    "\n",
    "        return tf.reduce_sum(weights*inputs, axis=-1) # (n_batch, n_feat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73636665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.117344Z",
     "iopub.status.busy": "2022-11-20T06:34:07.117080Z",
     "iopub.status.idle": "2022-11-20T06:34:07.121245Z",
     "shell.execute_reply": "2022-11-20T06:34:07.120306Z"
    },
    "papermill": {
     "duration": 0.013005,
     "end_time": "2022-11-20T06:34:07.123120",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.110115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedding_model = TFAutoModel.from_pretrained(DEBERTA_MODEL, config=deberta_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707b3c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.136009Z",
     "iopub.status.busy": "2022-11-20T06:34:07.135752Z",
     "iopub.status.idle": "2022-11-20T06:34:07.139609Z",
     "shell.execute_reply": "2022-11-20T06:34:07.138595Z"
    },
    "papermill": {
     "duration": 0.012545,
     "end_time": "2022-11-20T06:34:07.141686",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.129141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for encoder_block in embedding_model.deberta.encoder.layer[-:]:\n",
    "#     for layer in encoder_block.submodules:\n",
    "#         print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc0ffdf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.154590Z",
     "iopub.status.busy": "2022-11-20T06:34:07.154343Z",
     "iopub.status.idle": "2022-11-20T06:34:07.163488Z",
     "shell.execute_reply": "2022-11-20T06:34:07.162662Z"
    },
    "papermill": {
     "duration": 0.018003,
     "end_time": "2022-11-20T06:34:07.165498",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.147495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_masks = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"attention_masks\")\n",
    "    \n",
    "    embedding_model = TFAutoModel.from_pretrained(DEBERTA_MODEL, config=deberta_config)\n",
    "#     for encoder_block in embedding_model.deberta.encoder.layer[-5:]:\n",
    "#         for layer in encoder_block.submodules:\n",
    "#             layer.trainable = True\n",
    "    embedding_model.trainable = True\n",
    "\n",
    "    embedding_output = embedding_model(input_ids=input_ids, attention_mask=attention_masks)\n",
    "    x = tf.stack(embedding_output.hidden_states[-4:], axis = -1)\n",
    "    x = tf.reduce_mean(x, axis = 1)\n",
    "    x = WeightedAverage()(x)\n",
    "    x = tf.keras.layers.LayerNormalization(axis=1)(x)\n",
    "\n",
    "    #Output layer without activation function because regression task\n",
    "    x = tf.keras.layers.Dense(HPARAMS.num_fc_units)(x)\n",
    "    x = tf.keras.layers.Dense(HPARAMS.regr_units, \n",
    "                              activation=\"sigmoid\", \n",
    "                              kernel_initializer=tf.keras.initializers.GlorotUniform())(x)\n",
    "    output = tf.keras.layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e00862",
   "metadata": {
    "papermill": {
     "duration": 0.005689,
     "end_time": "2022-11-20T06:34:07.177257",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.171568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852b9d0",
   "metadata": {
    "papermill": {
     "duration": 0.005869,
     "end_time": "2022-11-20T06:34:07.189185",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.183316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "778b83f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.202252Z",
     "iopub.status.busy": "2022-11-20T06:34:07.201991Z",
     "iopub.status.idle": "2022-11-20T06:34:07.212110Z",
     "shell.execute_reply": "2022-11-20T06:34:07.211275Z"
    },
    "papermill": {
     "duration": 0.019006,
     "end_time": "2022-11-20T06:34:07.214215",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.195209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compile model with an approximation of layer-wise learning rate decay\n",
    "earlyStopping =  tf.keras.callbacks.EarlyStopping(monitor='val_MCRMSE', \n",
    "                                                  min_delta=1e-4, \n",
    "                                                  patience=3, \n",
    "                                                  verbose=1,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "lr_schedule_1 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5, \n",
    "    decay_steps=3910, \n",
    "    decay_rate=0.6)\n",
    "lr_schedule_2 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4, \n",
    "    decay_steps=3910, \n",
    "    decay_rate=0.6)\n",
    "optimizers = [tf.keras.optimizers.Adam(learning_rate=lr_schedule_1),\n",
    "              tf.keras.optimizers.Adam(learning_rate=lr_schedule_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b21d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.227172Z",
     "iopub.status.busy": "2022-11-20T06:34:07.226920Z",
     "iopub.status.idle": "2022-11-20T06:34:07.230950Z",
     "shell.execute_reply": "2022-11-20T06:34:07.229913Z"
    },
    "papermill": {
     "duration": 0.012983,
     "end_time": "2022-11-20T06:34:07.233270",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.220287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_train_token = batch_tokenize(X_train.loc[:500].to_list())\n",
    "# y_train = Y_train.loc[:500,:]\n",
    "# print(len(x_train_token), len(y_train))\n",
    "# tf.data.Dataset.from_tensor_slices((x_train_token, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1310394a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.246614Z",
     "iopub.status.busy": "2022-11-20T06:34:07.245841Z",
     "iopub.status.idle": "2022-11-20T06:34:07.250869Z",
     "shell.execute_reply": "2022-11-20T06:34:07.249997Z"
    },
    "papermill": {
     "duration": 0.01383,
     "end_time": "2022-11-20T06:34:07.253020",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.239190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f7c90",
   "metadata": {
    "papermill": {
     "duration": 0.005955,
     "end_time": "2022-11-20T06:34:07.264825",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.258870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d1818b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.277825Z",
     "iopub.status.busy": "2022-11-20T06:34:07.277556Z",
     "iopub.status.idle": "2022-11-20T06:34:07.282851Z",
     "shell.execute_reply": "2022-11-20T06:34:07.281881Z"
    },
    "papermill": {
     "duration": 0.01403,
     "end_time": "2022-11-20T06:34:07.284880",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.270850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pack_tf_dataset(inputs, outputs):\n",
    "    input1 = tf.data.Dataset.from_tensor_slices((inputs['input_ids']))\n",
    "    input2 = tf.data.Dataset.from_tensor_slices((inputs['attention_masks']))\n",
    "    label = tf.data.Dataset.from_tensor_slices((outputs))\n",
    "    combined_dataset = tf.data.Dataset.zip(({'input_ids':input1, 'attention_masks':input2},label))\n",
    "    return combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0a2c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T06:34:07.298244Z",
     "iopub.status.busy": "2022-11-20T06:34:07.297999Z",
     "iopub.status.idle": "2022-11-20T11:03:52.718008Z",
     "shell.execute_reply": "2022-11-20T11:03:52.716885Z"
    },
    "papermill": {
     "duration": 16186.228847,
     "end_time": "2022-11-20T11:03:53.519949",
     "exception": false,
     "start_time": "2022-11-20T06:34:07.291102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= FOLD 0 =========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 06:35:15.628236: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-20 06:35:28.462466: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 418s 478ms/step - loss: 0.1369 - MCRMSE: 0.4951 - val_loss: 0.1155 - val_MCRMSE: 0.4548\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 368s 471ms/step - loss: 0.1090 - MCRMSE: 0.4405 - val_loss: 0.1198 - val_MCRMSE: 0.4659\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 368s 470ms/step - loss: 0.0915 - MCRMSE: 0.4050 - val_loss: 0.1121 - val_MCRMSE: 0.4440\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 368s 470ms/step - loss: 0.0780 - MCRMSE: 0.3761 - val_loss: 0.1199 - val_MCRMSE: 0.4620\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 367s 470ms/step - loss: 0.0607 - MCRMSE: 0.3325 - val_loss: 0.1128 - val_MCRMSE: 0.4466\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 367s 470ms/step - loss: 0.0475 - MCRMSE: 0.2951 - val_loss: 0.1126 - val_MCRMSE: 0.4468\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "========================= FOLD 1 =========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 07:14:08.456129: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.04G (7557873664 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 420s 480ms/step - loss: 0.1346 - MCRMSE: 0.4874 - val_loss: 0.1144 - val_MCRMSE: 0.4491\n",
      "Epoch 2/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1029 - MCRMSE: 0.4277 - val_loss: 0.1090 - val_MCRMSE: 0.4388\n",
      "Epoch 3/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.0914 - MCRMSE: 0.4047 - val_loss: 0.1129 - val_MCRMSE: 0.4481\n",
      "Epoch 4/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.0820 - MCRMSE: 0.3846 - val_loss: 0.1093 - val_MCRMSE: 0.4406\n",
      "Epoch 5/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.0704 - MCRMSE: 0.3568 - val_loss: 0.1159 - val_MCRMSE: 0.4523\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n",
      "========================= FOLD 2 =========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "783/783 [==============================] - 420s 480ms/step - loss: 0.1345 - MCRMSE: 0.4882 - val_loss: 0.1175 - val_MCRMSE: 0.4592\n",
      "Epoch 2/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1041 - MCRMSE: 0.4302 - val_loss: 0.1109 - val_MCRMSE: 0.4453\n",
      "Epoch 3/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0955 - MCRMSE: 0.4130 - val_loss: 0.1065 - val_MCRMSE: 0.4364\n",
      "Epoch 4/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0882 - MCRMSE: 0.3977 - val_loss: 0.1064 - val_MCRMSE: 0.4341\n",
      "Epoch 5/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0818 - MCRMSE: 0.3828 - val_loss: 0.1112 - val_MCRMSE: 0.4441\n",
      "Epoch 6/20\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.0745 - MCRMSE: 0.3670 - val_loss: 0.1104 - val_MCRMSE: 0.4416\n",
      "Epoch 7/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0673 - MCRMSE: 0.3489 - val_loss: 0.1108 - val_MCRMSE: 0.4433\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "========================= FOLD 3 =========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "783/783 [==============================] - 420s 480ms/step - loss: 0.1378 - MCRMSE: 0.4941 - val_loss: 0.1135 - val_MCRMSE: 0.4499\n",
      "Epoch 2/20\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1080 - MCRMSE: 0.4385 - val_loss: 0.1089 - val_MCRMSE: 0.4394\n",
      "Epoch 3/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1018 - MCRMSE: 0.4253 - val_loss: 0.1120 - val_MCRMSE: 0.4454\n",
      "Epoch 4/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0967 - MCRMSE: 0.4153 - val_loss: 0.1086 - val_MCRMSE: 0.4388\n",
      "Epoch 5/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.0932 - MCRMSE: 0.4078 - val_loss: 0.1068 - val_MCRMSE: 0.4347\n",
      "Epoch 6/20\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.0905 - MCRMSE: 0.4023 - val_loss: 0.1092 - val_MCRMSE: 0.4397\n",
      "Epoch 7/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0868 - MCRMSE: 0.3938 - val_loss: 0.1067 - val_MCRMSE: 0.4353\n",
      "Epoch 8/20\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.0838 - MCRMSE: 0.3878 - val_loss: 0.1076 - val_MCRMSE: 0.4362\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "========================= FOLD 4 =========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "783/783 [==============================] - 420s 481ms/step - loss: 0.1515 - MCRMSE: 0.5167 - val_loss: 0.1208 - val_MCRMSE: 0.4656\n",
      "Epoch 2/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.1162 - MCRMSE: 0.4556 - val_loss: 0.1153 - val_MCRMSE: 0.4539\n",
      "Epoch 3/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1094 - MCRMSE: 0.4417 - val_loss: 0.1250 - val_MCRMSE: 0.4704\n",
      "Epoch 4/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.1059 - MCRMSE: 0.4345 - val_loss: 0.1163 - val_MCRMSE: 0.4557\n",
      "Epoch 5/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.1032 - MCRMSE: 0.4291 - val_loss: 0.1142 - val_MCRMSE: 0.4515\n",
      "Epoch 6/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.1009 - MCRMSE: 0.4244 - val_loss: 0.1101 - val_MCRMSE: 0.4428\n",
      "Epoch 7/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.0988 - MCRMSE: 0.4199 - val_loss: 0.1110 - val_MCRMSE: 0.4439\n",
      "Epoch 8/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.0971 - MCRMSE: 0.4165 - val_loss: 0.1098 - val_MCRMSE: 0.4418\n",
      "Epoch 9/20\n",
      "783/783 [==============================] - 371s 473ms/step - loss: 0.0958 - MCRMSE: 0.4140 - val_loss: 0.1124 - val_MCRMSE: 0.4474\n",
      "Epoch 10/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.0945 - MCRMSE: 0.4110 - val_loss: 0.1097 - val_MCRMSE: 0.4414\n",
      "Epoch 11/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.0934 - MCRMSE: 0.4087 - val_loss: 0.1136 - val_MCRMSE: 0.4481\n",
      "Epoch 12/20\n",
      "783/783 [==============================] - 371s 473ms/step - loss: 0.0924 - MCRMSE: 0.4068 - val_loss: 0.1108 - val_MCRMSE: 0.4436\n",
      "Epoch 13/20\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.0914 - MCRMSE: 0.4047 - val_loss: 0.1092 - val_MCRMSE: 0.4402\n",
      "Epoch 14/20\n",
      "783/783 [==============================] - 371s 473ms/step - loss: 0.0907 - MCRMSE: 0.4033 - val_loss: 0.1121 - val_MCRMSE: 0.4459\n",
      "Epoch 15/20\n",
      "783/783 [==============================] - 371s 473ms/step - loss: 0.0900 - MCRMSE: 0.4017 - val_loss: 0.1100 - val_MCRMSE: 0.4421\n",
      "Epoch 16/20\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.0893 - MCRMSE: 0.4002 - val_loss: 0.1110 - val_MCRMSE: 0.4435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "kf = KFold(n_splits=HPARAMS.kfolds)\n",
    "idx = 0\n",
    "for train_idx, valid_idx in kf.split(X_train):\n",
    "    print(f'========================= FOLD {idx} =========================')\n",
    "    x_train, x_valid = X_train.loc[train_idx], X_train.loc[valid_idx]\n",
    "    y_train, y_valid = Y_train.loc[train_idx,:], Y_train.loc[valid_idx, :]\n",
    "    \n",
    "    x_train_token = batch_tokenize(x_train.to_list())\n",
    "    x_valid_token = batch_tokenize(x_valid.to_list())\n",
    "    \n",
    "    # Wrap data in Dataset objects.\n",
    "    train_data = pack_tf_dataset(x_train_token, y_train)\n",
    "    train_data = train_data.cache().shuffle(BUFFER_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    train_data = train_data.batch(HPARAMS.batch_size)\n",
    "    valid_data = pack_tf_dataset(x_valid_token, y_valid)\n",
    "    valid_data = valid_data.batch(HPARAMS.batch_size)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizers_and_layers = [(optimizers[0], model.layers[:4]),\n",
    "                          (optimizers[1], model.layers[4:]),]\n",
    "    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss='huber_loss', # combination of l1 and l2\n",
    "            metrics=[MCRMSE],\n",
    "            )\n",
    "\n",
    "    # Callback\n",
    "    modelCheckpoint =  tf.keras.callbacks.ModelCheckpoint(filepath=f'best_weights_{idx}',\n",
    "                                                      save_weights_only=True,\n",
    "                                                      monitor='val_MCRMSE',\n",
    "                                                      mode='auto',\n",
    "                                                      save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "    history = model.fit(train_data, # [x_train_token[0], x_train_token[1]],\n",
    "                      validation_data=valid_data, #([x_valid_token[0], x_valid_token[1]], y_valid), \n",
    "                      epochs=HPARAMS.epochs,\n",
    "                      shuffle=True,\n",
    "                      callbacks=[earlyStopping, modelCheckpoint])\n",
    "    \n",
    "    idx += 1\n",
    "    del x_train, x_valid, y_train, y_valid\n",
    "    del model, history\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0fca9",
   "metadata": {
    "papermill": {
     "duration": 2.535433,
     "end_time": "2022-11-20T11:03:57.839250",
     "exception": false,
     "start_time": "2022-11-20T11:03:55.303817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "431bdff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T11:04:01.408415Z",
     "iopub.status.busy": "2022-11-20T11:04:01.407387Z",
     "iopub.status.idle": "2022-11-20T11:04:01.420030Z",
     "shell.execute_reply": "2022-11-20T11:04:01.419134Z"
    },
    "papermill": {
     "duration": 1.704173,
     "end_time": "2022-11-20T11:04:01.422074",
     "exception": false,
     "start_time": "2022-11-20T11:03:59.717901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(3, figsize=(10,7))\n",
    "# for idx in range(3):\n",
    "#     val_mcrmse = history_arr[idx].history['val_MCRMSE']\n",
    "#     train_mcrmse = history_arr[idx].history['MCRMSE']\n",
    "#     ax[idx].plot(range(len(val_mcrmse)), val_mcrmse, label='Val MCRMSE')\n",
    "#     ax[idx].plot(range(len(train_mcrmse)), train_mcrmse, label='Train MCRMSE')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6305e34",
   "metadata": {
    "papermill": {
     "duration": 1.780953,
     "end_time": "2022-11-20T11:04:05.000906",
     "exception": false,
     "start_time": "2022-11-20T11:04:03.219953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "535274e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T11:04:08.820531Z",
     "iopub.status.busy": "2022-11-20T11:04:08.820166Z",
     "iopub.status.idle": "2022-11-20T11:06:17.978716Z",
     "shell.execute_reply": "2022-11-20T11:06:17.977681Z"
    },
    "papermill": {
     "duration": 131.149717,
     "end_time": "2022-11-20T11:06:17.983463",
     "exception": false,
     "start_time": "2022-11-20T11:04:06.833746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
      "\n",
      "All the layers of TFDebertaV2Model were initialized from the model checkpoint at ../input/deberta/microsoft-deberta-v3-base/microsoft-deberta-v3-base/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "x_test_token = batch_tokenize(X_test.to_list())\n",
    "y_test_pred_arr = []\n",
    "for idx in range(HPARAMS.kfolds):\n",
    "    model = create_model()\n",
    "    model.load_weights(f'best_weights_{idx}')\n",
    "    result = model.predict([x_test_token['input_ids'], x_test_token['attention_masks']])\n",
    "    y_test_pred_arr.append(result)\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "y_test_pred = np.mean(y_test_pred_arr, axis = 0)\n",
    "# y_test_pred = y_test_pred/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "777a30af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T11:06:21.810892Z",
     "iopub.status.busy": "2022-11-20T11:06:21.810502Z",
     "iopub.status.idle": "2022-11-20T11:06:21.841552Z",
     "shell.execute_reply": "2022-11-20T11:06:21.840501Z"
    },
    "papermill": {
     "duration": 1.849401,
     "end_time": "2022-11-20T11:06:21.844326",
     "exception": false,
     "start_time": "2022-11-20T11:06:19.994925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.836082</td>\n",
       "      <td>2.779548</td>\n",
       "      <td>3.114091</td>\n",
       "      <td>3.018112</td>\n",
       "      <td>2.696621</td>\n",
       "      <td>2.701116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.626396</td>\n",
       "      <td>2.477513</td>\n",
       "      <td>2.687915</td>\n",
       "      <td>2.357104</td>\n",
       "      <td>2.151485</td>\n",
       "      <td>2.690220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.703728</td>\n",
       "      <td>3.446792</td>\n",
       "      <td>3.635209</td>\n",
       "      <td>3.622210</td>\n",
       "      <td>3.362167</td>\n",
       "      <td>3.409767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.836082  2.779548    3.114091     3.018112  2.696621   \n",
       "1  000BAD50D026  2.626396  2.477513    2.687915     2.357104  2.151485   \n",
       "2  00367BB2546B  3.703728  3.446792    3.635209     3.622210  3.362167   \n",
       "\n",
       "   conventions  \n",
       "0     2.701116  \n",
       "1     2.690220  \n",
       "2     3.409767  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.copy(deep=True)\n",
    "sub_df[Y_VARIABLES] = y_test_pred\n",
    "del sub_df['full_text']\n",
    "sub_df.to_csv('submission.csv',index=False)\n",
    "sub_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16357.766375,
   "end_time": "2022-11-20T11:06:27.155681",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-20T06:33:49.389306",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
